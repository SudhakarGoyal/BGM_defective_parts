{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_defects_path = glob.glob(os.path.join('/home/hitech/Downloads/YE358311_Fender_apron/YE358311_defects','*/*.jpg'))\n",
    "img_healthy_path = glob.glob(os.path.join('/home/hitech/Downloads/YE358311_Fender_apron/YE358311_Healthy','*.jpg'))\n",
    "img_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(img):\n",
    "    img = cv2.resize(img, (img_size,img_size))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "    \n",
    "\n",
    "def image_labels(path, label=0):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in path:\n",
    "        img = cv2.imread(i)\n",
    "        img = img_preprocessing(img)\n",
    "#         break\n",
    "        imgs.append(img)    \n",
    "        labels.append(label)\n",
    "    \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_healthy, labels_healthy  = image_labels(img_healthy_path,0)\n",
    "img_defective, labels_defective = image_labels(img_defects_path,1)\n",
    "\n",
    "final_images = img_healthy + img_defective\n",
    "labels = labels_healthy + labels_defective\n",
    "\n",
    "X = np.array(final_images)\n",
    "X = X.reshape(X.shape[0],img_size,img_size,3)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(img_healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, Y_train, Y_test =train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 158,756,993\n",
      "Trainable params: 158,755,073\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# classifier = tensorflow.keras.Sequential()\n",
    "# classifier.add(Conv2D(64,  (3, 3), padding='same', input_shape = (img_size, img_size,3)))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Activation('relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# classifier.add(Conv2D(128, (3, 3), padding='same'))\n",
    "# classifier.add(Conv2D(128, (3, 3), padding='same'))\n",
    "# classifier.add(Conv2D(128, (3, 3), padding='same'))\n",
    "\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Activation('relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# classifier.add(Conv2D(256, (3, 3), padding='same'))\n",
    "# classifier.add(Conv2D(256, (3, 3), padding='same'))\n",
    "# classifier.add(Conv2D(256, (3, 3), padding='same'))\n",
    "\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Activation('relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# classifier.add(Conv2D(512, (3, 3), padding = 'same'))\n",
    "# classifier.add(Conv2D(512, (3, 3), padding='same'))\n",
    "# classifier.add(Conv2D(512, (3, 3), padding='same'))\n",
    "\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Activation('relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# classifier.add(Flatten())\n",
    "\n",
    "# classifier.add(Dense(units = 4096, activation = 'relu'))#4096\n",
    "# classifier.add(Dense(units = 4096, activation = 'relu'))#4096\n",
    "# classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# classifier.summary()\n",
    "\n",
    "# classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.defective_parts_BGM_2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# history = classifier.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "#                      epochs=epochs,validation_data=(X_test, Y_test), callbacks=callbacks_list)\n",
    "\n",
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=2000,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size = 4\n",
    "testsplit = .2\n",
    "targetx = 224\n",
    "targety = 224\n",
    "learning_rate = 0.0001\n",
    "classes = 1\n",
    "# seed = random.randint(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image                  \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras.callbacks import *\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=90\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hitech/dl_env_2.7/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.layers[-1].outbound_nodes = []\n",
    "x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512,activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dense(1024,activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "predictions = Dense(classes, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learning_rate)\n",
    "loss = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hitech/dl_env_2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - 105s 2s/step - loss: 1.1666 - acc: 0.5893 - val_loss: 1.6756 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48000, saving model to weights.defective_parts_BGM_2.hdf5\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 1.1284 - acc: 0.6472 - val_loss: 2.3304 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.48000\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 1.1705 - acc: 0.5984 - val_loss: 1.4526 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.48000\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.6719 - acc: 0.7321 - val_loss: 0.9921 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.48000\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.7539 - acc: 0.6830 - val_loss: 1.0714 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.48000\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.6417 - acc: 0.7145 - val_loss: 0.9611 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.48000 to 0.56000, saving model to weights.defective_parts_BGM_2.hdf5\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.5517 - acc: 0.7767 - val_loss: 1.1985 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.5308 - acc: 0.7725 - val_loss: 1.0330 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.5549 - acc: 0.7770 - val_loss: 0.8380 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.5211 - acc: 0.7814 - val_loss: 0.6936 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.56000 to 0.64000, saving model to weights.defective_parts_BGM_2.hdf5\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.4077 - acc: 0.8526 - val_loss: 0.8121 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.64000\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3730 - acc: 0.8259 - val_loss: 0.7443 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.64000\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.4430 - acc: 0.8080 - val_loss: 0.8237 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.64000\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.4209 - acc: 0.7901 - val_loss: 0.7679 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.64000\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.5034 - acc: 0.7723 - val_loss: 0.7926 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.64000\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.3951 - acc: 0.8306 - val_loss: 0.7658 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.64000\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.4014 - acc: 0.8038 - val_loss: 0.8994 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.64000\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3618 - acc: 0.8350 - val_loss: 0.7931 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.64000\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3220 - acc: 0.8303 - val_loss: 1.0472 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.64000\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.3155 - acc: 0.8705 - val_loss: 0.9538 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.64000\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2721 - acc: 0.8884 - val_loss: 0.8681 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.64000\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3992 - acc: 0.8216 - val_loss: 0.9226 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.64000\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3743 - acc: 0.8303 - val_loss: 0.9118 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.64000\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3567 - acc: 0.8172 - val_loss: 0.7260 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64000\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.4123 - acc: 0.7948 - val_loss: 0.5929 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.64000 to 0.68000, saving model to weights.defective_parts_BGM_2.hdf5\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.2955 - acc: 0.8794 - val_loss: 0.8109 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.68000\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3430 - acc: 0.8306 - val_loss: 0.9106 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.68000\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.4213 - acc: 0.8348 - val_loss: 1.1612 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.68000\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3289 - acc: 0.8705 - val_loss: 1.4173 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.68000\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3017 - acc: 0.8618 - val_loss: 1.2284 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.68000\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3645 - acc: 0.8571 - val_loss: 0.9481 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.68000\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2975 - acc: 0.8884 - val_loss: 1.0236 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.68000\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2560 - acc: 0.8839 - val_loss: 0.9579 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.68000\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2879 - acc: 0.8975 - val_loss: 0.7788 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.68000\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3490 - acc: 0.8395 - val_loss: 0.7591 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.68000\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2574 - acc: 0.9062 - val_loss: 0.8751 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.68000\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2524 - acc: 0.8663 - val_loss: 1.0633 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.68000\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.3402 - acc: 0.8350 - val_loss: 1.0459 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.68000\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.3172 - acc: 0.8839 - val_loss: 1.9413 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.68000\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 93s 2s/step - loss: 0.2908 - acc: 0.8663 - val_loss: 1.2586 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.68000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                     epochs=epochs,validation_data=(X_test, Y_test), callbacks=callbacks_list, \n",
    "                              steps_per_epoch=len(X_train) / batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
